{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b583618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Weaviate Academy\n",
    "# Course: 101T - Working with text data\n",
    "#\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import weaviate.classes.config as wc\n",
    "import weaviate.classes.query as wq\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from weaviate.util import generate_uuid5\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "}\n",
    "\n",
    "# \n",
    "# Connect to a local Weaviate instance.\n",
    "#\n",
    "client = weaviate.connect_to_local(headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b806d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9753e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the movie data.\n",
    "data_url = \"https://raw.githubusercontent.com/weaviate-tutorials/edu-datasets/main/movies_data_1990_2024.json\"\n",
    "resp = requests.get(data_url)\n",
    "df = pd.DataFrame(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0376f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/.well-known/live \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Creating movie collection\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'grpcMaxMessageSize': 104858000, 'hostname': 'http://[::]:8080', 'modules': {'generative-anthropic': {'documentationHref': 'https://docs.anthropic.com/en/api/getting-started', 'name': 'Generative Search - Anthropic'}, 'generative-anyscale': {'documentationHref': 'https://docs.anyscale.com/endpoints/overview', 'name': 'Generative Search - Anyscale'}, 'generative-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html', 'name': 'Generative Search - AWS'}, 'generative-cohere': {'documentationHref': 'https://docs.cohere.com/reference/chat', 'name': 'Generative Search - Cohere'}, 'generative-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#completion-task', 'name': 'Generative Search - Databricks'}, 'generative-friendliai': {'documentationHref': 'https://docs.friendli.ai/openapi/create-chat-completions', 'name': 'Generative Search - FriendliAI'}, 'generative-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/chat/test-chat-prompts', 'name': 'Generative Search - Google'}, 'generative-mistral': {'documentationHref': 'https://docs.mistral.ai/api/', 'name': 'Generative Search - Mistral'}, 'generative-nvidia': {'documentationHref': 'https://docs.api.nvidia.com/nim/reference/llm-apis', 'name': 'Generative Search - NVIDIA'}, 'generative-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started', 'name': 'Generative Search - OctoAI (deprecated)'}, 'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions', 'name': 'Generative Search - OpenAI'}, 'generative-xai': {'documentationHref': 'https://docs.x.ai/docs/overview', 'name': 'Generative Search - xAI'}, 'multi2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/', 'name': 'Cohere Module'}, 'multi2vec-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings', 'name': 'Google Multimodal Module'}, 'multi2vec-jinaai': {'documentationHref': 'https://jina.ai/embeddings/', 'name': 'JinaAI CLIP Module'}, 'multi2vec-nvidia': {'documentationHref': 'https://docs.api.nvidia.com/nim/reference/retrieval-apis', 'name': 'NVIDIA CLIP Module'}, 'multi2vec-voyageai': {'documentationHref': 'https://docs.voyageai.com/docs/multimodal-embeddings', 'name': 'VoyageAI Multi Modal Module'}, 'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/', 'name': 'Reranker - Cohere'}, 'reranker-jinaai': {'documentationHref': 'https://jina.ai/reranker', 'name': 'Reranker - Jinaai'}, 'reranker-nvidia': {'documentationHref': 'https://docs.api.nvidia.com/nim/reference/retrieval-apis', 'name': 'Reranker - NVIDIA'}, 'reranker-voyageai': {'documentationHref': 'https://docs.voyageai.com/reference/reranker-api', 'name': 'Reranker - VoyageAI'}, 'text2colbert-jinaai': {'documentationHref': 'https://jina.ai/embeddings/', 'name': 'JinaAI Module'}, 'text2vec-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html', 'name': 'AWS Module'}, 'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/', 'name': 'Cohere Module'}, 'text2vec-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#embedding-task', 'name': 'Databricks Foundation Models Module - Embeddings'}, 'text2vec-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings', 'name': 'Google Module'}, 'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task', 'name': 'Hugging Face Module'}, 'text2vec-jinaai': {'documentationHref': 'https://jina.ai/embeddings/', 'name': 'JinaAI Module'}, 'text2vec-mistral': {'documentationHref': 'https://docs.mistral.ai/api/#operation/createEmbedding', 'name': 'Mistral Module'}, 'text2vec-nvidia': {'documentationHref': 'https://docs.api.nvidia.com/nim/reference/retrieval-apis', 'name': 'NVIDIA Module'}, 'text2vec-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started', 'name': 'OctoAI Module (deprecated)'}, 'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings', 'name': 'OpenAI Module'}, 'text2vec-voyageai': {'documentationHref': 'https://docs.voyageai.com/docs/embeddings', 'name': 'VoyageAI Module'}, 'text2vec-weaviate': {'documentationHref': 'https://api.embedding.weaviate.io', 'name': 'Weaviate Embedding Module'}}, 'version': '1.31.2'}\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/schema/Movie \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Deleting existing Movie collection.\n",
      "INFO:httpx:HTTP Request: DELETE http://localhost:8080/v1/schema/Movie \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8080/v1/schema \"HTTP/1.1 200 OK\"\n",
      "INFO:root:created Movie collection\n"
     ]
    }
   ],
   "source": [
    "# Create a movie collection.\n",
    "\n",
    "try:\n",
    "    assert client.is_live()\n",
    "    logger.info(f'Creating movie collection')\n",
    "    logger.info(client.get_meta())\n",
    "    \n",
    "    if client.collections.exists(\"Movie\"):\n",
    "        logger.info(\"Deleting existing Movie collection.\")\n",
    "        client.collections.delete(\"Movie\")\n",
    "\n",
    "    client.collections.create(\n",
    "    name=\"Movie\",\n",
    "    properties=[\n",
    "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"overview\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"vote_average\", data_type=wc.DataType.NUMBER),\n",
    "        wc.Property(name=\"genre_ids\", data_type=wc.DataType.INT_ARRAY),\n",
    "        wc.Property(name=\"release_date\", data_type=wc.DataType.DATE),\n",
    "        wc.Property(name=\"tmdb_id\", data_type=wc.DataType.INT),\n",
    "    ],\n",
    "    # Define the vectorizer module\n",
    "    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(),\n",
    "    # Define the generative module\n",
    "    generative_config=wc.Configure.Generative.openai()\n",
    "    )\n",
    "\n",
    "finally:\n",
    "    logger.info('created Movie collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9faceb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/schema/Movie \"HTTP/1.1 200 OK\"\n",
      "680it [00:00, 5746.28it/s]\n",
      "INFO:root:movies.batch.failed_objects = []\n",
      "INFO:root:imported movies\n"
     ]
    }
   ],
   "source": [
    "# Import movies\n",
    "\n",
    "try:\n",
    "        # Get the collection\n",
    "    movies = client.collections.get(\"Movie\")\n",
    "\n",
    "    # Enter context manager\n",
    "    with movies.batch.fixed_size(batch_size=200) as batch:\n",
    "        # Loop through the data\n",
    "        for i, movie in tqdm(df.iterrows()):\n",
    "            # Convert data types\n",
    "            # Convert a JSON date to `datetime` and add time zone information\n",
    "            release_date = datetime.strptime(movie[\"release_date\"], \"%Y-%m-%d\").replace(\n",
    "                tzinfo=timezone.utc\n",
    "            )\n",
    "            # Convert a JSON array to a list of integers\n",
    "            genre_ids = json.loads(movie[\"genre_ids\"])\n",
    "\n",
    "            # Build the object payload\n",
    "            movie_obj = {\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"overview\": movie[\"overview\"],\n",
    "                \"vote_average\": movie[\"vote_average\"],\n",
    "                \"genre_ids\": genre_ids,\n",
    "                \"release_date\": release_date,\n",
    "                \"tmdb_id\": movie[\"id\"],\n",
    "            }\n",
    "\n",
    "            # Add object to batch queue\n",
    "            batch.add_object(\n",
    "                properties=movie_obj,\n",
    "                uuid=generate_uuid5(movie[\"id\"])\n",
    "                # references=reference_obj  # You can add references here\n",
    "            )\n",
    "            # Batcher automatically sends batches\n",
    "\n",
    "    # Check for failed objects\n",
    "    if len(movies.batch.failed_objects) > 0:\n",
    "        logger.error(f\"Failed to import {len(movies.batch.failed_objects)} objects\")\n",
    "    else:\n",
    "        logger.info(f'{movies.batch.failed_objects = }')\n",
    "\n",
    "finally:\n",
    "    logger.info('imported movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbb880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query = dystopian future\n",
      "In Time 2011\n",
      "Distance to query: 0.564\n",
      "\n",
      "Mad Max: Fury Road 2015\n",
      "Distance to query: 0.574\n",
      "\n",
      "I, Robot 2004\n",
      "Distance to query: 0.585\n",
      "\n",
      "Gattaca 1997\n",
      "Distance to query: 0.587\n",
      "\n",
      "Children of Men 2006\n",
      "Distance to query: 0.593\n",
      "\n",
      "BM25 query for history\n",
      "A Beautiful Mind 2001\n",
      "BM25 score: 2.723\n",
      "\n",
      "Legends of the Fall 1994\n",
      "BM25 score: 2.483\n",
      "\n",
      "Night at the Museum 2006\n",
      "BM25 score: 2.412\n",
      "\n",
      "Hacksaw Ridge 2016\n",
      "BM25 score: 2.367\n",
      "\n",
      "The Butterfly Effect 2004\n",
      "BM25 score: 2.202\n",
      "\n",
      "Hybrid Query\n",
      "GoodFellas 1990\n",
      "Hybrid score: 0.700\n",
      "\n",
      "A Beautiful Mind 2001\n",
      "Hybrid score: 0.628\n",
      "\n",
      "The Butterfly Effect 2004\n",
      "Hybrid score: 0.549\n",
      "\n",
      "Hidden Figures 2016\n",
      "Hybrid score: 0.424\n",
      "\n",
      "Hancock 2008\n",
      "Hybrid score: 0.391\n",
      "\n",
      "Query using release_date filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/weaviate-academy/.venv/lib/python3.12/site-packages/weaviate/warnings.py:186: UserWarning: Con002: You are using the datetime object 2020-01-01 00:00:00 without a timezone. The timezone will be set to UTC.\n",
      "            To use a different timezone, specify it in the datetime object. For example:\n",
      "            datetime.datetime(2021, 1, 1, 0, 0, 0, tzinfo=datetime.timezone(-datetime.timedelta(hours=2))).isoformat() = 2021-01-01T00:00:00-02:00\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Adam Project 2022\n",
      "Distance to query: 0.659\n",
      "\n",
      "Jurassic World Dominion 2022\n",
      "Distance to query: 0.663\n",
      "\n",
      "Dune 2021\n",
      "Distance to query: 0.666\n",
      "\n",
      "Greenland 2020\n",
      "Distance to query: 0.673\n",
      "\n",
      "Don't Look Up 2021\n",
      "Distance to query: 0.674\n",
      "\n",
      "Single prompt query: Translate this into French\n",
      "In Time\n",
      "À temps\n",
      "Mad Max: Fury Road\n",
      "Mad Max: Fury Road\n",
      "I, Robot\n",
      "Moi, Robot\n",
      "Gattaca\n",
      "Gattaca\n",
      "Children of Men\n",
      "Les enfants des hommes\n",
      "Grouped task prompt query: What do these movies have in common?\n",
      "In Time\n",
      "Mad Max: Fury Road\n",
      "I, Robot\n",
      "Gattaca\n",
      "Children of Men\n",
      "These movies all take place in a dystopian future where society has undergone significant changes and faces various challenges. They explore themes such as inequality, survival, technology, and the consequences of human actions.\n",
      "finished with queries\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Perform query\n",
    "    print(\"Query = dystopian future\")\n",
    "    response = movies.query.near_text(\n",
    "        query=\"dystopian future\", limit=5, return_metadata=wq.MetadataQuery(distance=True)\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(\n",
    "            o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "        )  # Print the title and release year (note the release date is a datetime object)\n",
    "        print(\n",
    "            f\"Distance to query: {o.metadata.distance:.3f}\\n\"\n",
    "        )  # Print the distance of the object from the query\n",
    "\n",
    "    # Perform query\n",
    "    print(\"BM25 query for history\")\n",
    "    response = movies.query.bm25(\n",
    "        query=\"history\", limit=5, return_metadata=wq.MetadataQuery(score=True)\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(\n",
    "            o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "        )  # Print the title and release year (note the release date is a datetime object)\n",
    "        print(\n",
    "            f\"BM25 score: {o.metadata.score:.3f}\\n\"\n",
    "        )  # Print the BM25 score of the object from the query\n",
    "\n",
    "    # Hybrid Query\n",
    "    print(\"Hybrid Query\")\n",
    "    response = movies.query.hybrid(\n",
    "        query=\"history\", limit=5, return_metadata=wq.MetadataQuery(score=True)\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(\n",
    "            o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "        )  # Print the title and release year (note the release date is a datetime object)\n",
    "        print(\n",
    "            f\"Hybrid score: {o.metadata.score:.3f}\\n\"\n",
    "        )  # Print the hybrid search score of the object from the query\n",
    "\n",
    "    # Perform query\n",
    "    print(\"Query using release_date filter\")\n",
    "    response = movies.query.near_text(\n",
    "        query=\"dystopian future\",\n",
    "        limit=5,\n",
    "        return_metadata=wq.MetadataQuery(distance=True),\n",
    "        filters=wq.Filter.by_property(\"release_date\").greater_than(datetime(2020, 1, 1))\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(\n",
    "            o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "        )  # Print the title and release year (note the release date is a datetime object)\n",
    "        print(\n",
    "            f\"Distance to query: {o.metadata.distance:.3f}\\n\"\n",
    "        )  # Print the distance of the object from the query\n",
    "\n",
    "    # Single Prompt\n",
    "    print(\"Single prompt query: Translate this into French\")\n",
    "\n",
    "    response = movies.generate.near_text(\n",
    "        query=\"dystopian future\",\n",
    "        limit=5,\n",
    "        single_prompt=\"Translate this into French: {title}\"\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(o.properties[\"title\"])  # Print the title\n",
    "        print(o.generated)  # Print the generated text (the title, in French)\n",
    "\n",
    "    # Generative Search\n",
    "    print(\"Grouped task prompt query: What do these movies have in common?\")\n",
    "    response = movies.generate.near_text(\n",
    "        query=\"dystopian future\",\n",
    "        limit=5,\n",
    "        grouped_task=\"What do these movies have in common?\",\n",
    "        # grouped_properties=[\"title\", \"overview\"]  # Optional parameter; for reducing prompt length\n",
    "    )\n",
    "\n",
    "    # Inspect the response\n",
    "    for o in response.objects:\n",
    "        print(o.properties[\"title\"])  # Print the title\n",
    "    print(response.generated)  # Print the generated text (the commonalities between them)\n",
    "\n",
    "finally:\n",
    "    print('finished with queries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5787d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
